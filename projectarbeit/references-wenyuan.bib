
@inproceedings{makarov-clematide-2020-semi,
    title = "Semi-supervised Contextual Historical Text Normalization",
    author = "Makarov, Peter  and
      Clematide, Simon",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.650",
    doi = "10.18653/v1/2020.acl-main.650",
    pages = "7284--7295",
    abstract = "Historical text normalization, the task of mapping historical word forms to their modern counterparts, has recently attracted a lot of interest (Bollmann, 2019; Tang et al., 2018; Lusetti et al., 2018; Bollmann et al., 2018;Robertson and Goldwater, 2018; Bollmannet al., 2017; Korchagina, 2017). Yet, virtually all approaches suffer from the two limitations: 1) They consider a fully supervised setup, often with impractically large manually normalized datasets; 2) Normalization happens on words in isolation. By utilizing a simple generative normalization model and obtaining powerful contextualization from the target-side language model, we train accurate models with unlabeled historical data. In realistic training scenarios, our approach often leads to reduction in manually normalized data at the same accuracy levels.",
}

@phdthesis{Bollmann2018,
  author      = {Marcel Bollmann},
  title       = {Normalization of historical texts with neural network models},
  type        = {doctoralthesis},
  school      = {Ruhr-Universit{\"a}t Bochum, Universit{\"a}tsbibliothek},
  doi       = {10.13154/294-6213},
  year        = {2018},
}

@inproceedings{bollmann-2019-large,
    title = "A Large-Scale Comparison of Historical Text Normalization Systems",
    author = "Bollmann, Marcel",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1389",
    doi = "10.18653/v1/N19-1389",
    pages = "3885--3898",
    abstract = "There is no consensus on the state-of-the-art approach to historical text normalization. Many techniques have been proposed, including rule-based methods, distance metrics, character-based statistical machine translation, and neural encoder{--}decoder models, but studies have used different datasets, different evaluation methods, and have come to different conclusions. This paper presents the largest study of historical text normalization done so far. We critically survey the existing literature and report experiments on eight languages, comparing systems spanning all categories of proposed normalization techniques, analysing the effect of training data quantity, and using different evaluation methods. The datasets and scripts are made publicly available.",
}

@inproceedings{korchagina-2017-normalizing,
    title = "Normalizing Medieval {G}erman Texts: from rules to deep learning",
    author = "Korchagina, Natalia",
    booktitle = "Proceedings of the {N}o{D}a{L}i{D}a 2017 Workshop on Processing Historical Language",
    month = may,
    year = "2017",
    address = "Gothenburg",
    publisher = {Link{\"o}ping University Electronic Press},
    url = "https://www.aclweb.org/anthology/W17-0504",
    pages = "12--17",
}

@inproceedings{hamalainen-etal-2019-revisiting,
    title = "Revisiting {NMT} for Normalization of Early {E}nglish Letters",
    author = {H{\"a}m{\"a}l{\"a}inen, Mika  and
      S{\"a}ily, Tanja  and
      Rueter, Jack  and
      Tiedemann, J{\"o}rg  and
      M{\"a}kel{\"a}, Eetu},
    booktitle = "Proceedings of the 3rd Joint {SIGHUM} Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",
    month = jun,
    year = "2019",
    address = "Minneapolis, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-2509",
    doi = "10.18653/v1/W19-2509",
    pages = "71--75",
    abstract = "This paper studies the use of NMT (neural machine translation) as a normalization method for an early English letter corpus. The corpus has previously been normalized so that only less frequent deviant forms are left out without normalization. This paper discusses different methods for improving the normalization of these deviant forms by using different approaches. Adding features to the training data is found to be unhelpful, but using a lexicographical resource to filter the top candidates produced by the NMT model together with lemmatization improves results.",
}

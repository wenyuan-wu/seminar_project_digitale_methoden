
model-ensemble3: !Experiment
  exp_global: &exp_global !ExpGlobal
    model_file: '../marian_preprocessed/{EXP}.mod'
    log_file: '../marian_preprocessed/{EXP}.log'
    default_layer_dim: 300
    dropout: 0.2

  model: !DefaultTranslator
    src_reader: !PlainTextReader
      _xnmt_id: the_src_reader
      vocab: !Vocab {vocab_file: "../marian_preprocessed/train.src.vocab"}
    trg_reader: !PlainTextReader
      _xnmt_id: the_trg_reader
      vocab: !Vocab {vocab_file: "../marian_preprocessed/train.trg.vocab"}
    src_embedder: !SimpleWordEmbedder
      emb_dim: 60
    encoder: !BiLSTMSeqTransducer
      layers: 1
      input_dim: 60
      hidden_dim: 300
    attender: !MlpAttender
      hidden_dim: 300
    trg_embedder: !SimpleWordEmbedder
      emb_dim: 60
    decoder: !MlpSoftmaxDecoder
      rnn_layer: !UniLSTMSeqTransducer
        layers: 1
      trg_embed_dim: 60
      mlp_layer: !MLP
        hidden_dim: 300
      bridge: !CopyBridge {}

  train: !SimpleTrainingRegimen
    batcher: !SentShuffleBatcher
      batch_size: 25
    trainer: !AdamTrainer
      alpha: 0.001
    run_for_epochs: 1000
    lr_decay: 0.01
    lr_decay_times: 0
    patience: 5

    src_file: "../marian_preprocessed/train.src"
    trg_file: "../marian_preprocessed/train.trg"
    dev_tasks:
      - !AccuracyEvalTask
        eval_metrics: accuracy
        src_file: "../marian_preprocessed/dev.src"
        ref_file: "../marian_preprocessed/dev.trg"
        hyp_file: "../marian_preprocessed/dev.hyp"

  evaluate: &evaluate
    - !AccuracyEvalTask
      eval_metrics: accuracy
      src_file: "../marian_preprocessed/dev.src"
      ref_file: "../marian_preprocessed/dev.trg"
      hyp_file: "../marian_preprocessed/dev.predictions"
      inference: !SimpleInference
        search_strategy: !BeamSearch
          beam_size: 5
